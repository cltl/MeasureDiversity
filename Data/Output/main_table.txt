\newcommand{\paperdata}[2]{\citeauthor{#1} (\citeyear{#1}) & \cite{#1} & #2}

\begin{tabular}{lllllrrrrrrl}
\toprule
 Name                & Ref   & Technique        & BLEU   & Meteor   &   ASL &   SDSL &   Types &   MSTTR &   BiTTR &   \textbackslash{}\%Novel & Coverage   \\
\midrule
 \paperdata{Dai_2017_ICCV}{GAN with policy gradient}                        & 20.7   & 22.4     &   9.8 &   1.63 &    1922 &    0.23 &    0.55 &      87.7 & 0.15       \\
 \paperdata{liu2017mat}{Object detector+LSTM}                        & 32.3   & 25.8     &  10.3 &   1.32 &     598 &    0.17 &    0.38 &      50.1 & 0.05       \\
 \paperdata{mun2017text}{Text-guided attention LSTM}                        & 32.6   & 25.7     &   9.4 &   1.12 &    1009 &    0.16 &    0.38 &      50   & 0.08       \\
 \paperdata{Shetty:2016:ESC:2983563.2983571}{CNN\&scene features+LSTM}                     & 31.9   & 25.2     &   9   &   1.03 &    1112 &    0.15 &    0.34 &      43   & 0.08       \\
 \paperdata{Shetty_2017_ICCV}{GAN with Gumbel softmax}                     & --     & 23.6     &   9.4 &   1.31 &    2611 &    0.24 &    0.54 &      80.5 & 0.20       \\
 \paperdata{tavakoli2017paying}{CNN\&saliency features+LSTM}                   & 28.7   & 23.5     &   9.2 &   1.03 &     917 &    0.15 &    0.33 &      38.8 & 0.07       \\
 \paperdata{vinyals2017show}{CNN+LSTM}                    & 32.1   & 25.7     &  10.1 &   1.28 &     953 &    0.21 &    0.43 &      90.5 & 0.07       \\
 \paperdata{wu2017image}{Attribute vector+LSTM}                         & 31.0   & 25.0     &   9.1 &   1.03 &     849 &    0.14 &    0.32 &      44.5 & 0.06       \\
 \paperdata{zhou2017watch}{CNN+text-conditional LSTM}                       & 30.0   & 24.8     &   9.3 &   1.2  &    1334 &    0.22 &    0.51 &      60.1 & 0.10       \\
 Val                 &       & Reference corpus & --     & --       &  11.3 &   2.61 &    9200 &    0.32 &    0.72 &      95.3 & --         \\
\bottomrule
\end{tabular}
Caption: The number of Types and Tokens, Average Sentence Length (ASL), and
normalized Type-Token Ratio (nTTR, number of types per 1K tokens). Note that the
results for the validation set are averaged over the parallel descriptions. The total
number of types in the validation set is 17557, and the total
number of tokens is 2296146. The ASL and nTTR for the training
set are similar to the validation set.
------------
Train stats:
average_sentence_length		11.3
std_sentence_length		2.63
avg_types		12374.2
type_token_ratio		0.31
bittr		0.70
total_types		23454
total_tokens		4695422
------------